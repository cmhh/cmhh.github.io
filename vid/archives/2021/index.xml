<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2021 on cmhh</title>
    <link>/archives/2021/</link>
    <description>Recent content in 2021 on cmhh</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 14 Aug 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/archives/2021/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Data Services from Existing PostgreSQL Databases</title>
      <link>/2021/2021-08-14-data-services-from-postgres/</link>
      <pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/2021-08-14-data-services-from-postgres/</guid>
      <description>Overview A while back I made a small data service which took time series data I scraped from the web, and used it to make a data service. I used Play Framework for the API itself, and PostgreSQL as the back-end. The service wasn&amp;rsquo;t terribly complicated to put together, and I do think that building bespoke services as the need arises, rather than aiming for some sort of generic framework, can be useful.</description>
    </item>
    
    <item>
      <title>Online Learning with Akka</title>
      <link>/2021/2021-08-08-online-learning-with-akka/</link>
      <pubDate>Sun, 08 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/2021-08-08-online-learning-with-akka/</guid>
      <description>Overview In a previous post, we looked at how we could consume messages in a Kafka topic, and use those messages for online training of a classifier. In this post, we look at how Akka could be used to solve the same problem, in broadly the same way. Akka is an implementation of the actor model, and is particularly well suited for building event-driven, reactive systems since the actors involved communicate exclusively by sending and reacting to messages.</description>
    </item>
    
    <item>
      <title>Online Learning with Apache Kafka</title>
      <link>/2021/2021-07-30-online-learning-with-apache-kafka/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/2021-07-30-online-learning-with-apache-kafka/</guid>
      <description>Overview I recently came across a scenario at work that would, like so many things in practice, be particularly well modelled as an ordered set of events. The messages would have a large number of uses in practice, but one would involve using them to train some sort of predictive model. Moreover, the messages would be arriving in real-time, and the patterns underpinning the messages might well change over time. Based on previous research, Kafka seemed like it would be a good fit, though I don&amp;rsquo;t yet have a huge amount of practical experience using it.</description>
    </item>
    
    <item>
      <title>A Brief Look at Apache Sedona</title>
      <link>/2021/2021-04-19-a-brief-look-at-apache-sedona/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/2021-04-19-a-brief-look-at-apache-sedona/</guid>
      <description>Overview Apache Sedona, formerly GeoSpark, is a library that let&amp;rsquo;s us make spatial RDDs and DataFrames in Apache Spark, as well as to run spatial queries. Feature classes can get very large, and so being able to run various geoprocessing tasks in a distributed context seems worthwhile. So, in this post, we take a very brief look at Apache Sedona.
This post is not intended to provide comprehensive coverage of the features provided by Sedonaâ€“that would be pretty unrealistic for a short blog post.</description>
    </item>
    
  </channel>
</rss>
