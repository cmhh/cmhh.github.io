<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>cmhh  | A Brief Look at Apache Sedona</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.1/css/bulma.min.css" />
    <link href="../../css/highlight/atom-one-dark-reasonable.css" rel='stylesheet' type='text/css' />
    <link rel="stylesheet" href="../../css/blog.css" />
    <link rel="stylesheet" href="../../css/custom.css" />
</head>
<body>

    
    <nav class="navbar is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a class="navbar-item" href="../../">Home</a>
            
        </div>
    </nav>
    

    
    <section class="hero is-info is-medium">
        <div class="hero-body" style="background-image: url(/img/bg-blog-2.jpg);">
            <div class="container has-text-centered">
                <br>
                <h1 class="title is-size-1">
                    
                        A Brief Look at Apache Sedona
                    
                </h1>
                
            </div>
        </div>
    </section>


<div class="container">
    <div class="section">
    

<div class="columns">
    <div class="column is-9">
        <div class="tile is-child box">
            <div class="content">
                <h1 id="overview">Overview</h1>
<p><a href="https://sedona.apache.org/">Apache Sedona</a>, formerly GeoSpark, is a library that let&rsquo;s us make spatial RDDs and DataFrames in Apache Spark, as well as to run spatial queries.  Feature classes can get very large, and so being able to run various geoprocessing tasks in a distributed context seems worthwhile.  So, in this post, we take a very brief look at Apache Sedona.</p>
<p>This post is not intended to provide comprehensive coverage of the features provided by Sedona–that would be pretty unrealistic for a short blog post.  Rather, we will just run a couple of simple examples which will give some sense of both the overall interface and also <code>performance</code> relative to some other common tools.</p>
<p>For the purposes of illustration, we consider just two examples:</p>
<ul>
<li>dissolve a set of polygons via <code>ST_Union_Aggr</code> / <code>ST_Union</code></li>
<li>attach polygon attributes to a set of points using <code>ST_Intersects</code></li>
</ul>
<p>The polygons we will dissolve are <a href="https://koordinates.com/from/datafinder.stats.govt.nz/layer/105173/">Meshblock Higher Geographies 2021 (high definition)</a> provided by <a href="https://stats.govt.nz">Stats NZ</a>, and the grouping variable used will be Regional Council.  For the task of attaching polygon attributes to points, we borrow the meshblock code from the meshblock 2021 feature class above, and we attach it to <a href="https://koordinates.com/from/data.linz.govt.nz/layer/53353/">NZ Street Address</a> provided by <a href="https://www.linz.govt.nz/">Land Information New Zealand (LINZ)</a>.</p>
<p>Neither of these tasks is <em>massive</em>, with each being comfortably achievable on a single, typically endowed laptop.  In this setting, PostGIS is faster than Sedona, but Sedona offers a more scalable solution overall.  Sedona can perform as well as PostGIS when using a cluster with several workers, and Sedona should scale to very large problems where vertical scaling of PostGIS would become challenging.</p>
<h1 id="environment">Environment</h1>
<p>The majority of the examples in this post were executed on a Dell XPS 15 laptop with 16GB of DDR4 RAM @ 2667MHz, and 12 x Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz.  In this environment, we run Spark in pseudo-distributed mode.  That is, we use multiple workers, but all on a single host, and using an exclusively local filesystem.</p>
<p>Spark is really intended to be used in a genuinely distributed environment, though, and so for comparison we also run our code using AWS Elastic MapReduce.  We use emr-6.2.0, with Hadoop 3.2.1 and Spark 3.0.1, and the instances themselves are m5.xlarge which have 4 virtual cores and 16GiB of RAM.  We vary the number of worker nodes, choosing configurations with both 6 and 12 workers.  Importantly, in this scenario we also use a distributed filesystem (HDFS).</p>
<h1 id="example-1---dissolve-meshblock-by-regional-council">Example 1 - Dissolve Meshblock by Regional Council</h1>
<p>As noted, for our first example we take the union of all meshblocks by Regional Council.  Visually:</p>
<p><img src="assets/dissolve01.png" alt=""></p>
<p>We discuss each approach in detail below, but a high-level summary is as follows:</p>
<div class="three-col-container">
<div class="three-col ttle">PostGIS</div>
<div class="three-col ttle">R</div>
<div class="three-col ttle">Sedona</div>
<div class="three-col">
```sql
SELECT
  regc2021_v, 
  ST_Multi(ST_Union(geom)) as geom
FROM 
  statsnz.meshblock2021
GROUP BY 
  regc2021_v
ORDER BY
  regc2021_v
<pre><code>&lt;/div&gt;
&lt;div class=&quot;three-col&quot;&gt;
```r
rc &lt;- mbhg %&gt;%
  group_by(REGC2021_V) %&gt;%
  summarise(n = n())
  
  
  
  
  
  
  
  
  
</code></pre></div>
<div class="three-col">
```scala
val rc = spark.sql("""
  SELECT 
    REGC2021_V, 
    ST_Union_Aggr(geometry) 
      as geometry 
  FROM 
    mb 
  GROUP BY
    REGC2021_V 
  ORDER BY
    REGC2021_V
""")
```
</div>
<div class="three-col">121 seconds</div>
<div class="three-col">124 seconds</div>
<div class="three-col">152 seconds (stand-alone)</div>
</div>
<p>Sedona will scale to some extent–when run on a cluster using Elastic MapReduce (6.2.0), Sedona took 122 seconds with 6 workers, and 108 seconds with 12 workers.  Other optimisations are likely possible when tuning various cluster parameters, such as number of workers, driver memory, and so on.</p>
<h2 id="postgis">PostGIS</h2>
<p>Assuming we have stored the meshblock features in a PostGIS table called <code>statsnz.meshblock2021</code>, we can dissolve them by running the following SQL query:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql"><span style="color:#66d9ef">SELECT</span>
  regc2021_v, ST_Multi(ST_Union(geom)) <span style="color:#66d9ef">as</span> geom
<span style="color:#66d9ef">FROM</span> 
  statsnz.meshblock2021
<span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> 
  regc2021_v
<span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span>
  regc2021_v
</code></pre></div><p>This took 121 seconds.</p>
<h2 id="r--sf">R / <code>sf</code></h2>
<p>To import the meshblock data in R, we run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">library</span>(sf)

<span style="color:#a6e22e">system.time</span>({
  mbhg <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">st_read</span>(<span style="color:#e6db74">&#34;meshblock-higher-geographies-2021-high-definition.shp&#34;</span>)  
})
</code></pre></div><p>This took 3 seconds, and the resulting data frame occupies 300MB in memory.  To dissolve it, we run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">rc <span style="color:#f92672">&lt;-</span> mbhg <span style="color:#f92672">%&gt;%</span>
  <span style="color:#a6e22e">group_by</span>(REGC2021_V) <span style="color:#f92672">%&gt;%</span>
  <span style="color:#a6e22e">summarise</span>(n <span style="color:#f92672">=</span> <span style="color:#a6e22e">n</span>())
</code></pre></div><p>This took around 124 seconds, and the resulting data frame occupies 3.9MB in memory.</p>
<h2 id="sedona---local">Sedona - Local</h2>
<p>We first load our meshblock feature class as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">import</span> org.apache.sedona.core.formatMapper.shapefileParser.ShapefileReader

<span style="color:#66d9ef">val</span> mbrdd <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">ShapefileReader</span><span style="color:#f92672">.</span>readToPolygonRDD<span style="color:#f92672">(</span>
  sc<span style="color:#f92672">,</span> <span style="color:#75715e">// the cluster SparkContext
</span><span style="color:#75715e"></span>  <span style="color:#e6db74">&#34;meshblock-higher-geographies-2021-high-definition&#34;</span>
<span style="color:#f92672">)</span>
</code></pre></div><p>The type of <code>mbrdd</code> is <code>PolygonRDD</code>, which is-a <code>SpatialRDD</code>.  <code>SpatialRDD</code> has a standard <code>RDD</code> under the hood, and has methods for adding indexes, doing spatial joins, and so on.  However, we can convert <code>SpatialRDD</code>s to <code>DataFrame</code>s, and then run reasonably standard looking SQL queries on the result.  This is probably going to be the most accessible option for those who aren&rsquo;t terribly familiar with Spark or Java / Scala.  To convert to <code>DataFrame</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">import</span> org.apache.sedona.sql.utils.<span style="color:#f92672">{</span><span style="color:#a6e22e">Adapter</span><span style="color:#f92672">,</span> <span style="color:#a6e22e">SedonaSQLRegistrator</span><span style="color:#f92672">}</span>

<span style="color:#a6e22e">SedonaSQLRegistrator</span><span style="color:#f92672">.</span>registerAll<span style="color:#f92672">(</span>spark<span style="color:#f92672">)</span>

<span style="color:#66d9ef">val</span> mbdf <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">Adapter</span>
  <span style="color:#f92672">.</span>toDf<span style="color:#f92672">(</span>mbrdd<span style="color:#f92672">,</span> spark<span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>repartition<span style="color:#f92672">(</span><span style="color:#ae81ff">32</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>persist
</code></pre></div><p>The result is a <code>DataFrame</code> where our geometry is stored as type <code>Geometry</code> in a column called geometry, and calling <code>registerAll(spark)</code> ensures that the <code>Geometry</code> type is understood by Spark.  For example, we create a user-defined function which calculates the area of a polygon:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">import</span> org.locationtech.jts.geom.Geometry
<span style="color:#66d9ef">import</span> org.apache.spark.sql.functions.<span style="color:#f92672">{</span>col<span style="color:#f92672">,</span> udf<span style="color:#f92672">}</span>

<span style="color:#66d9ef">val</span> f<span style="color:#66d9ef">:</span> <span style="color:#f92672">(</span><span style="color:#66d9ef">x:</span> <span style="color:#66d9ef">Geometry</span><span style="color:#f92672">)</span> <span style="color:#f92672">=&gt;</span> x<span style="color:#f92672">.</span>getArea
</code></pre></div><p>and use it to derive an area column:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">mbdf
  <span style="color:#f92672">.</span>withColumn<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;area&#34;</span><span style="color:#f92672">,</span> f<span style="color:#f92672">(</span>col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;geometry&#34;</span><span style="color:#f92672">)))</span>
  <span style="color:#f92672">.</span>select<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;MB2021_V1_&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;REGC2021_V&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;REGC2021_2&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;area&#34;</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>limit<span style="color:#f92672">(</span><span style="color:#ae81ff">10</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>show
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plaintext" data-lang="plaintext">+----------+----------+------------------+--------------------+
|MB2021_V1_|REGC2021_V|        REGC2021_2|                area|
+----------+----------+------------------+--------------------+
|   0973300|        03|    Waikato Region|   68346.86758174733|
|   4002221|        06|Hawke&#39;s Bay Region|  42925.980450310104|
|   4008822|        13| Canterbury Region|   37448.43920328615|
|   2311100|        13| Canterbury Region|3.8148438963027686E7|
|   2815503|        13| Canterbury Region|  24410.008602414582|
|   0221305|        02|   Auckland Region|    884246.943146247|
|   1152900|        03|    Waikato Region| 4.621434800254852E7|
|   4011098|        13| Canterbury Region|   8207.470212947434|
|   4011489|        13| Canterbury Region|1.0198131361068603E7|
|   2830201|        14|      Otago Region|   96059.66604287364|
+----------+----------+------------------+--------------------+
</code></pre></div><p>Either way, we now create a view from the <code>DataFrame</code> which we can use from our SQL context:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">mbdf<span style="color:#f92672">.</span>createOrReplaceTempView<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;mb&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>and then use to write standard looking spatial SQL queries.  For example, we now add an area column in an arguably more straightforward manner:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">spark
  <span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;&#34;&#34; 
</span><span style="color:#e6db74">    SELECT 
</span><span style="color:#e6db74">      MB2021_V1_, 
</span><span style="color:#e6db74">      REGC2021_V, 
</span><span style="color:#e6db74">      REGC2021_2, 
</span><span style="color:#e6db74">      ST_AREA(geometry) as area
</span><span style="color:#e6db74">    FROM
</span><span style="color:#e6db74">      mb
</span><span style="color:#e6db74">    LIMIT 10
</span><span style="color:#e6db74">  &#34;&#34;&#34;</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>show
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plaintext" data-lang="plaintext">+----------+----------+------------------+--------------------+
|MB2021_V1_|REGC2021_V|        REGC2021_2|                area|
+----------+----------+------------------+--------------------+
|   0973300|        03|    Waikato Region|   68346.86758174733|
|   4002221|        06|Hawke&#39;s Bay Region|  42925.980450310104|
|   4008822|        13| Canterbury Region|   37448.43920328615|
|   2311100|        13| Canterbury Region|3.8148438963027686E7|
|   2815503|        13| Canterbury Region|  24410.008602414582|
|   0221305|        02|   Auckland Region|    884246.943146247|
|   1152900|        03|    Waikato Region| 4.621434800254852E7|
|   4011098|        13| Canterbury Region|   8207.470212947434|
|   4011489|        13| Canterbury Region|1.0198131361068603E7|
|   2830201|        14|      Otago Region|   96059.66604287364|
+----------+----------+------------------+--------------------+
</code></pre></div><p>More importantly, we can dissolve the meshblocks by region as desired as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> rc <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span>
  <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">  SELECT 
</span><span style="color:#e6db74">    REGC2021_V, 
</span><span style="color:#e6db74">    ST_Union_Aggr(geometry) as geometry 
</span><span style="color:#e6db74">  FROM 
</span><span style="color:#e6db74">    mb 
</span><span style="color:#e6db74">  GROUP BY
</span><span style="color:#e6db74">    REGC2021_V 
</span><span style="color:#e6db74">  ORDER BY
</span><span style="color:#e6db74">    REGC2021_V
</span><span style="color:#e6db74">  &#34;&#34;&#34;</span> 
<span style="color:#f92672">)</span>
</code></pre></div><p>Spark SQL execution is lazy, so we need to trigger an action in order to see how long this actually takes.  I like to write a little function I can re-use for timing purposes as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">def</span> timeit<span style="color:#f92672">[</span><span style="color:#66d9ef">T</span><span style="color:#f92672">](</span>block<span style="color:#66d9ef">:</span> <span style="color:#f92672">=&gt;</span>T<span style="color:#f92672">)</span><span style="color:#66d9ef">:</span> <span style="color:#f92672">(</span><span style="color:#66d9ef">T</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">Double</span><span style="color:#f92672">)</span> <span style="color:#66d9ef">=</span> <span style="color:#f92672">{</span>
  <span style="color:#66d9ef">val</span> startTime <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">System</span><span style="color:#f92672">.</span>nanoTime
  <span style="color:#66d9ef">val</span> res<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">T</span> <span style="color:#f92672">=</span> block
  <span style="color:#f92672">(</span>res<span style="color:#f92672">,</span> <span style="color:#f92672">(</span><span style="color:#a6e22e">System</span><span style="color:#f92672">.</span>nanoTime <span style="color:#f92672">-</span> startTime<span style="color:#f92672">)</span> <span style="color:#f92672">/</span> <span style="color:#ae81ff">1</span>e9<span style="color:#f92672">)</span>
<span style="color:#f92672">}</span>
</code></pre></div><p>So:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> <span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">,</span> t<span style="color:#f92672">)</span> <span style="color:#66d9ef">=</span> timeit <span style="color:#f92672">{</span> rc<span style="color:#f92672">.</span>show <span style="color:#f92672">}</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">t<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Double</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">152.024319529</span>
</code></pre></div><p>At 152 seconds this is a little slower than PostGIS, but pretty reasonable all the same.  However, there is a pretty big caveat here.  Spark is pretty sophisticated, and in practice performance will vary a lot depending on how things are configured.  We can vary the number of executors, the number of cores each executor can use, driver memory, and so on, and so on.  In this case we did not spend any time tuning these parameters, but we did deliberately repartition the input meshblock features into 36 chunks, and this has a dramatic effect on performance.  The following chart shows runtime as a function of the number of partitions:</p>
<pre><code class="language-{r" data-lang="{r">library(ggplot2)
library(plotly)

df &lt;- data.frame(
  partitions = c(1, 6, 12, 36, 54, 75, 100, 200),
  time = c(4905, 729, 310, 152, 138, 158, 170, 269)
)

p &lt;- ggplot(data = df, aes(x = partitions, y = time)) + 
  geom_line() + 
  geom_point() +
  xlab(&quot;number of partitions&quot;) +
  ylab(&quot;runtime (seconds)&quot;)
ggplotly(p)
</code></pre><p>The machine this task was run on has 12 cores, and the best performance seems to be roughly where there are 3 times as many partitions as cores.</p>
<p>Note that those familiar with Spark could attempt to do things a bit more&hellip; primitively.  Looking again at the original object, <code>mbrdd</code>, we can get the underlying <code>RDD</code> as:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">mbrdd<span style="color:#f92672">.</span>getRawSpatialRDD<span style="color:#f92672">.</span>rdd
</code></pre></div><p>This is essentially just a collection of objects of type <code>Geometry</code>.  We can call a method <code>getUserData</code> on a <code>Geometry</code> object to get the attributes associated with a feature as a single tab-delimited string.  The 24th field is the regional council code, and we can use this to create a pair <code>RDD</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> pairrdd <span style="color:#66d9ef">=</span> mbrdd
  <span style="color:#f92672">.</span>getRawSpatialRDD<span style="color:#f92672">.</span>rdd
  <span style="color:#f92672">.</span>groupBy<span style="color:#f92672">(</span>x <span style="color:#66d9ef">=&gt;</span> x<span style="color:#f92672">.</span>getUserData<span style="color:#f92672">.</span>toString<span style="color:#f92672">.</span>split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\t&#34;</span><span style="color:#f92672">)(</span><span style="color:#ae81ff">24</span><span style="color:#f92672">))</span>
</code></pre></div><p>We can then fold the geometries in each key-value pair naively as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> rc <span style="color:#66d9ef">=</span> pairrdd
  <span style="color:#f92672">.</span>map<span style="color:#f92672">(</span>x <span style="color:#66d9ef">=&gt;</span> <span style="color:#f92672">{</span>
    <span style="color:#66d9ef">val</span> y <span style="color:#66d9ef">=</span> x<span style="color:#f92672">.</span>_2
    <span style="color:#f92672">(</span>x<span style="color:#f92672">.</span>_1 <span style="color:#f92672">-&gt;</span> y<span style="color:#f92672">.</span>tail<span style="color:#f92672">.</span>foldLeft<span style="color:#f92672">(</span>y<span style="color:#f92672">.</span>head<span style="color:#f92672">)(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">.</span>union<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">)))</span>
  <span style="color:#f92672">})</span>
</code></pre></div><p>This does in fact give us what we want, however the approach turns out to be way too naive, taking 45 minutes all up!  That said, it would scale if we threw enough workers at it.  Still, at times this sort of approach will be useful.</p>
<h2 id="sedona---elastic-mapreduce">Sedona - Elastic MapReduce</h2>
<p>When deployed on Elastic MapReduce, the code required is the same, with very minor differences.  In this case, we naively set the number of partitions for each input feature class to be the number of cores times the number of workers.  In addition, when using EMR we store our source shapefiles in the Hadoop filesystem.  A cluster with 6 workers was able to dissolve the features as required in 122 seconds, and a cluster with 12 workers dissolved the features in 108 seconds.</p>
<h1 id="example-2---intersection-of-addresses-and-meshblocks">Example 2 - Intersection of Addresses and Meshblocks</h1>
<p>For the next example, we find the meshblock polygon each of our address points belongs to, and we then borrow attributes from the containing polygon, attaching them directly as attributes of each address point.  Visually:</p>
<p><img src="assets/intersect01.png" alt=""></p>
<p>We discuss each approach in detail below, but a high-level summary is as follows:</p>
<div class="three-col-container">
<div class="three-col ttle">PostGIS</div>
<div class="three-col ttle">R</div>
<div class="three-col ttle">Sedona</div>
<div class="three-col">
```sql
SELECT 
  addr.address_id, 
  addr.full_add_1,  
  mb.mb2021_v1_, 
  addr.geom 
FROM
  linz.address addr, 
  statsnz.meshblock2021 mb 
WHERE 
  st_intersects(addr.geom, mb.geom)
<pre><code>&lt;/div&gt;
&lt;div class=&quot;three-col&quot;&gt;
```r
sf::st_intersection(
  select(
    addr, ADDRESS_ID, FULL_ADD_1
  ), 
  select(mbhg, MB2021_V1_)
) 







</code></pre></div>
<div class="three-col">
```scala
val rc = spark.sql("""
  SELECT 
    REGC2021_V, 
    ST_Union_Aggr(geometry) 
      as geometry 
  FROM 
    mb 
  GROUP BY
    REGC2021_V 
  ORDER BY
    REGC2021_V
""")
```
</div>
<div class="three-col">193 seconds</div>
<div class="three-col">3194 seconds</div>
<div class="three-col">268 seconds (stand-alone)</div>
</div>
<p>As before, Sedona will scale to some extent–when run on a cluster using Elastic MapReduce (6.2.0), Sedona took 154 seconds with 6 workers, and 110 seconds with 12 workers.  Other optimisations are likely possible when tuning various cluster parameters, such as number of workers, driver memory, and so on.  R is extremely slow in this case because we do not create and exploit any kind of spatial indexing.</p>
<h2 id="postgis-1">PostGIS</h2>
<p>Assuming we have address points stored in a PostGIS table called <code>linz.address</code>, and meshblock as before in <code>statsnz.meshblock2021</code>, we can borrow attributes from each address' enclosing meshblock as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql"><span style="color:#66d9ef">SELECT</span> 
  addr.address_id, 
  addr.full_add_1,  
  mb.mb2021_v1_, 
  addr.geom 
<span style="color:#66d9ef">FROM</span>
  linz.address addr, 
  statsnz.meshblock2021 mb 
<span style="color:#66d9ef">WHERE</span> 
  st_intersects(addr.geom, mb.geom)
</code></pre></div><p>This took 193 seconds.  Note that to ensure this query can be executed efficiently, it is necessary to ensure spatial indexes are created for both input features ahead of time.  For example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql"><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">INDEX</span> address_geom_idx <span style="color:#66d9ef">ON</span> linz.address <span style="color:#66d9ef">using</span> GIST(geom);
<span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">INDEX</span> meshblock2021_geom_idx <span style="color:#66d9ef">ON</span> statsnz.meshblock2021 <span style="color:#66d9ef">using</span> GIST(geom);
</code></pre></div><h2 id="r--sf-1">R / <code>sf</code></h2>
<p>To import the address data in R, we run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">system.time</span>({
  addr <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">st_read</span>(<span style="color:#e6db74">&#34;nz-street-address.shp&#34;</span>)  
})
</code></pre></div><p>This took 40 seconds, and the resulting data frame occupies 1.5GB in memory.  To intersect this with the meshblock feature class:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">sf<span style="color:#f92672">::</span><span style="color:#a6e22e">st_intersection</span>(
  <span style="color:#a6e22e">select</span>(addr, ADDRESS_ID, FULL_ADD_1), 
  <span style="color:#a6e22e">select</span>(mbhg, MB2021_V1_)
) 
</code></pre></div><p>This took 3194 seconds, or 53 minutes.  This is slow because there is no way to make use of a spatial index, and to find which meshblock an address is in will require a full scan of the meshblock feature class for each address.  Note, though, that it would be easy to parallelise this task simply by breaking the address input into ranges and intersecting each concurrently.</p>
<h2 id="sedona---local-1">Sedona - Local</h2>
<p>To create a <code>DataFrame</code> containing addresses, we run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> addrpath <span style="color:#66d9ef">=</span> <span style="color:#e6db74">&#34;shp/linz/nz-street-address&#34;</span>
<span style="color:#66d9ef">val</span> addrrdd <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">ShapefileReader</span><span style="color:#f92672">.</span>readToGeometryRDD<span style="color:#f92672">(</span>sc<span style="color:#f92672">,</span> addrpath<span style="color:#f92672">)</span>
<span style="color:#66d9ef">val</span> addr <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">Adapter</span><span style="color:#f92672">.</span>toDf<span style="color:#f92672">(</span>addrrdd<span style="color:#f92672">,</span> spark<span style="color:#f92672">).</span>repartition<span style="color:#f92672">(</span><span style="color:#ae81ff">32</span><span style="color:#f92672">).</span>persist
addr<span style="color:#f92672">.</span>createOrReplaceTempView<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;addr&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>And to intersect this with the meshblock <code>DataFrame</code>, we run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> addrmb <span style="color:#66d9ef">=</span> spark
  <span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">  SELECT 
</span><span style="color:#e6db74">    addr.ADDRESS_ID, 
</span><span style="color:#e6db74">    addr.FULL_ADD_1, 
</span><span style="color:#e6db74">    mb.MB2021_V1_, 
</span><span style="color:#e6db74">    addr.geometry 
</span><span style="color:#e6db74">  FROM 
</span><span style="color:#e6db74">    addr, 
</span><span style="color:#e6db74">    mb  
</span><span style="color:#e6db74">  WHERE 
</span><span style="color:#e6db74">    st_intersects(addr.geometry, bb.geometry)
</span><span style="color:#e6db74">  &#34;&#34;&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>This took 268 seconds.  This is reasonable, but still a little slower than using PostGIS.  As for the PostGIS query, it is necessary to ensure that spatial indexes are used in order for this query to run efficiently.  One way of doing this is to ensure we set the Spark config <code>sedona.global.index</code> to <code>true</code>.  Without doing this, the query will run <em>much</em> slower.</p>
<p>As before, we can get similar results using <code>RDD</code>s directly.  For example, we can produce a new pair <code>RDD</code> that contains meshblocks as a key, and all the points within the meshblock as values in the following way:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">import</span> org.apache.sedona.core.enums.IndexType
<span style="color:#66d9ef">import</span> org.apache.sedona.core.spatialOperator.JoinQuery

addrrdd<span style="color:#f92672">.</span>spatialPartitioning<span style="color:#f92672">(</span><span style="color:#a6e22e">GridType</span><span style="color:#f92672">.</span><span style="color:#a6e22e">KDBTREE</span><span style="color:#f92672">)</span>
mbrdd<span style="color:#f92672">.</span>spatialPartitioning<span style="color:#f92672">(</span>addrrdd<span style="color:#f92672">.</span>getPartitioner<span style="color:#f92672">())</span>
addrrdd<span style="color:#f92672">.</span>buildIndex<span style="color:#f92672">(</span><span style="color:#a6e22e">IndexType</span><span style="color:#f92672">.</span><span style="color:#a6e22e">QUADTREE</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">true</span><span style="color:#f92672">)</span>
mbrdd<span style="color:#f92672">.</span>buildIndex<span style="color:#f92672">(</span><span style="color:#a6e22e">IndexType</span><span style="color:#f92672">.</span><span style="color:#a6e22e">QUADTREE</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">true</span><span style="color:#f92672">)</span>

<span style="color:#66d9ef">val</span> result <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">JoinQuery</span><span style="color:#f92672">.</span><span style="color:#a6e22e">SpatialJoinQuery</span><span style="color:#f92672">(</span>addrrdd<span style="color:#f92672">,</span> mbrdd<span style="color:#f92672">,</span> <span style="color:#66d9ef">true</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">false</span><span style="color:#f92672">)</span>
</code></pre></div><p>Again, those familiar with Spark already will find objects like this relatively easy to work with.  For example, to print a list of meshblock and address ID pairs:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">result<span style="color:#f92672">.</span>rdd<span style="color:#f92672">.</span>flatMap<span style="color:#f92672">(</span>x <span style="color:#66d9ef">=&gt;</span> <span style="color:#f92672">{</span>
  <span style="color:#66d9ef">val</span> mbid <span style="color:#66d9ef">=</span> x<span style="color:#f92672">.</span>_1<span style="color:#f92672">.</span>getUserData<span style="color:#f92672">.</span>toString<span style="color:#f92672">.</span>split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\t&#34;</span><span style="color:#f92672">)(</span><span style="color:#ae81ff">1</span><span style="color:#f92672">)</span>
  <span style="color:#66d9ef">val</span> addrids <span style="color:#66d9ef">=</span> x<span style="color:#f92672">.</span>_2<span style="color:#f92672">.</span>asScala<span style="color:#f92672">.</span>map<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">.</span>getUserData<span style="color:#f92672">.</span>toString<span style="color:#f92672">.</span>split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\t&#34;</span><span style="color:#f92672">)(</span><span style="color:#ae81ff">1</span><span style="color:#f92672">))</span>
  addrids<span style="color:#f92672">.</span>map<span style="color:#f92672">((</span>mbid<span style="color:#f92672">,</span> <span style="color:#66d9ef">_</span><span style="color:#f92672">))</span>
<span style="color:#f92672">}).</span>take<span style="color:#f92672">(</span><span style="color:#ae81ff">10</span><span style="color:#f92672">).</span>foreach<span style="color:#f92672">(</span>println<span style="color:#f92672">)</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plaintext" data-lang="plaintext">(4003499,2099993)
(4003499,2099992)
(4003499,2099994)
(1619000,2099934)
(2817502,2010408)
(3031002,2099960)
(4008278,2099958)
(4007449,2100082)
(4006988,2099944)
(1618904,2099935)
</code></pre></div><h2 id="sedona---elastic-mapreduce-1">Sedona - Elastic MapReduce</h2>
<p>When deployed on Elastic MapReduce, the code required is the same, with very minor differences.  In this case, we again naively set the number of partitions for each input feature class to be the number of cores times the number of workers.  A cluster with 6 workers was able to dissolve the features as required in 154 seconds, and a cluster with 12 workers dissolved the features in 110 seconds</p>
<h1 id="appendix---getting-a-repl-up-and-running">Appendix - Getting a REPL Up and Running</h1>
<h2 id="sbt-console"><code>sbt console</code></h2>
<p>One of the easier ways to get running with Spark is to set up a basic sbt project.  We can then use the sbt console to run code interactively, or else output a jar file which can be used with <code>spark-shell</code>.  To get going, all we need is a <code>build.sbt</code> file with the following content:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">name <span style="color:#66d9ef">:</span><span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;sedonatest&#34;&#34;&#34;</span>
version <span style="color:#66d9ef">:</span><span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;0.0.1&#34;</span>

scalaVersion <span style="color:#66d9ef">:</span><span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;2.12.13&#34;</span>
scalacOptions <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#34;-Ydelambdafy:inline&#34;</span>

libraryDependencies <span style="color:#f92672">++=</span> <span style="color:#a6e22e">Seq</span><span style="color:#f92672">(</span>
  <span style="color:#e6db74">&#34;org.apache.spark&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;spark-core&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;3.0.1&#34;</span><span style="color:#f92672">,</span> 
  <span style="color:#e6db74">&#34;org.apache.spark&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;spark-sql&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;3.0.1&#34;</span><span style="color:#f92672">,</span> 
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-core-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-sql-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-viz-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-viz-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.locationtech.jts&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;jts-core&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.18.1&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.geotools&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;gt-main&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;24.0&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.geotools&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;gt-referencing&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;24.0&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.geotools&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;gt-epsg-hsql&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;24.0&#34;</span>
<span style="color:#f92672">)</span>

resolvers <span style="color:#f92672">++=</span> <span style="color:#a6e22e">Seq</span><span style="color:#f92672">(</span>
  <span style="color:#e6db74">&#34;Open Source Geospatial Foundation Repository&#34;</span> at <span style="color:#e6db74">&#34;https://repo.osgeo.org/repository/release/&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;Apache Software Foundation Snapshots&#34;</span> at <span style="color:#e6db74">&#34;https://repository.apache.org/content/groups/snapshots&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;Java.net repository&#34;</span> at <span style="color:#e6db74">&#34;https://download.java.net/maven/2&#34;</span>
<span style="color:#f92672">)</span>
</code></pre></div><p>From within the project folder, we first run <code>sbt</code> to get an interactive build shell, and then <code>console</code> to get to the Scala REPL.  Run this way, the Spark and Sedona libraries will both be available.</p>
<p>Unlike <code>spark-shell</code>, <code>sbt console</code> will not provide a <code>SparkSession</code> instance.  Assuming we&rsquo;re running in standalone mode, we can create one as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> spark<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">SparkSession</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">SparkSession</span>
    <span style="color:#f92672">.</span>builder
    <span style="color:#f92672">.</span>master<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;local[*]&#34;</span><span style="color:#f92672">)</span>
    <span style="color:#f92672">.</span>appName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;sedonatest&#34;</span><span style="color:#f92672">)</span>
    <span style="color:#f92672">.</span>config<span style="color:#f92672">(</span>
      <span style="color:#e6db74">&#34;spark.serializer&#34;</span><span style="color:#f92672">,</span> 
      <span style="color:#e6db74">&#34;org.apache.spark.serializer.KryoSerializer&#34;</span>
    <span style="color:#f92672">)</span> 
    <span style="color:#f92672">.</span>config<span style="color:#f92672">(</span>
      <span style="color:#e6db74">&#34;spark.kryo.registrator&#34;</span><span style="color:#f92672">,</span> 
      <span style="color:#e6db74">&#34;org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator&#34;</span>
    <span style="color:#f92672">)</span> 
    <span style="color:#f92672">.</span>config<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;sedona.global.index&#34;</span><span style="color:#f92672">,</span><span style="color:#e6db74">&#34;true&#34;</span><span style="color:#f92672">)</span>
    <span style="color:#f92672">.</span>getOrCreate
</code></pre></div><p>And, of course, to get a <code>SparkContext</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> sc <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>sparkContext
</code></pre></div><h2 id="spark-shell"><code>spark-shell</code></h2>
<p>If we have access to a Spark cluster and wish to use <code>spark-shell</code> instead, then we&rsquo;d modify the dependencies in <code>build.sbt</code> as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">libraryDependencies <span style="color:#f92672">++=</span> <span style="color:#a6e22e">Seq</span><span style="color:#f92672">(</span>
  <span style="color:#e6db74">&#34;org.apache.spark&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;spark-core&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;3.0.1&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;provided&#34;</span><span style="color:#f92672">,</span> 
  <span style="color:#e6db74">&#34;org.apache.spark&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;spark-sql&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;3.0.1&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;provided&#34;</span><span style="color:#f92672">,</span> 
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-core-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-sql-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-viz-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.apache.sedona&#34;</span> <span style="color:#f92672">%%</span> <span style="color:#e6db74">&#34;sedona-viz-3.0&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.0.0-incubating&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.locationtech.jts&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;jts-core&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;1.18.1&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.geotools&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;gt-main&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;24.0&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.geotools&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;gt-referencing&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;24.0&#34;</span><span style="color:#f92672">,</span>
  <span style="color:#e6db74">&#34;org.geotools&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;gt-epsg-hsql&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;24.0&#34;</span>
<span style="color:#f92672">)</span>
</code></pre></div><p>We&rsquo;d typically make a so-called &lsquo;fat jar&rsquo;, and adding <code>% &quot;provided&quot;</code> ensures the Spark dependencies, which will be present already, aren&rsquo;t included in the archive.  Note that we&rsquo;re using Spark 3.0.1 here, so adjust this as required to match whatever is installed in your cluster.</p>
<p>To make a fat jar, we ensure <code>./project/assembly.sbt</code> is present with the following content:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">addSbtPlugin<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;com.eed3si9n&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;sbt-assembly&#34;</span> <span style="color:#f92672">%</span> <span style="color:#e6db74">&#34;0.14.10&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>We can then run <code>sbt assembly</code> from the project root, producing, in this case, <code>./target/scala-2.12/sedonatest-assembly-0.0.1.jar</code>.  We then start <code>spark-shell</code> as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark-shell --jars sedonatest-assembly-0.0.1.jar
</code></pre></div><p>If we wish the jar file to have a different name, <code>sedonatest.jar</code> for example, we&rsquo;d add the following to <code>build.sbt</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">assemblyJarName in assembly <span style="color:#66d9ef">:</span><span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;sedonatest.jar&#34;</span>
</code></pre></div><p>Note that if we get duplicate dependency errors when running <code>assembly</code>, then we can add something like the following to <code>build.sbt</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">assemblyMergeStrategy in assembly <span style="color:#66d9ef">:</span><span style="color:#f92672">=</span> <span style="color:#f92672">{</span>
  <span style="color:#66d9ef">case</span> <span style="color:#a6e22e">PathList</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;META-INF&#34;</span><span style="color:#f92672">,</span> xs <span style="color:#66d9ef">@</span> <span style="color:#66d9ef">_</span><span style="color:#f92672">*)</span> <span style="color:#66d9ef">=&gt;</span> <span style="color:#a6e22e">MergeStrategy</span><span style="color:#f92672">.</span>discard 
  <span style="color:#66d9ef">case</span> x <span style="color:#66d9ef">=&gt;</span> <span style="color:#a6e22e">MergeStrategy</span><span style="color:#f92672">.</span>first
<span style="color:#f92672">}</span>
</code></pre></div><p>Elastic MapReduce uses YARN as a resource manager, so we also omit the following line when creating our <code>SparkSession</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">  <span style="color:#f92672">.</span>master<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;local[*]&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><h1 id="appendix---data">Appendix - Data</h1>
<p><a href="https://koordinates.com/from/datafinder.stats.govt.nz/layer/105173/">Meshblock Higher Geographies 2021 (high definition)</a> is a set of 53596 polygons covering the full extent of New Zealand.  It was downloaded in ESRI shapefile format.  Zipped, it weighs in at 155MB, and unzipped, 504MB.  All other higher geographies maintained by Stats NZ are collections of meshblocks, and the attribute table provided includes concordances.</p>
<p><a href="https://koordinates.com/from/data.linz.govt.nz/layer/53353/">NZ Street Address</a> is a set of 2107573 address points.  Zipped, the shapefile is 178MB, and unzipped it is 2.8GB.  The address points are split into 3 different shapefiles when using <a href="https://koordinates.com">Koordinates</a>, which we collapsed into one post-download.</p>
<p>Note that Sedona seems to require shapefiles to be stored in a certain way.  Specifically, that we put shapefiles in a folder which has the same name as the individual components.  For the meshblocks, this means:</p>
<pre><code>meshblock-higher-geographies-2021-high-definition
├── meshblock-higher-geographies-2021-high-definition.cpg
├── meshblock-higher-geographies-2021-high-definition.dbf
├── meshblock-higher-geographies-2021-high-definition.prj
├── meshblock-higher-geographies-2021-high-definition.shp
├── meshblock-higher-geographies-2021-high-definition.shx
├── meshblock-higher-geographies-2021-high-definition.txt
└── meshblock-higher-geographies-2021-high-definition.xml
</code></pre><p>Most other systems don&rsquo;t require us to collect the components in a folder in this way, even if it might be sensible to organise things this way.  In R, for example, we&rsquo;d just refer to the <code>shp</code> component and the rest would be detected for as.  For example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">addr <span style="color:#f92672">&lt;-</span> sf<span style="color:#f92672">::</span><span style="color:#a6e22e">st_read</span>(<span style="color:#e6db74">&#34;nz-street-address.shp&#34;</span>)
</code></pre></div><p>Note that when using Elastic MapReduce, we need to copy our input features to the Hadoop filesystem.  For example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hdfs dfs -copyFromLocal meshblock-higher-geographies-2021-high-definition /user/hadoop/
</code></pre></div>
            </div>
        </div>
    </div>
    <div class="column is-3">
        <div class="card">
    <div class="card-content">
        <h1 class="title is-5">Tags</h1>
        <div class="tags">
        
            <span class="tag"><a href="../../tags/akka-http">akka-http</a></span>
        
            <span class="tag"><a href="../../tags/docker">docker</a></span>
        
            <span class="tag"><a href="../../tags/geoserver">geoserver</a></span>
        
            <span class="tag"><a href="../../tags/geospark">geospark</a></span>
        
            <span class="tag"><a href="../../tags/geospatial">geospatial</a></span>
        
            <span class="tag"><a href="../../tags/nodejs">nodejs</a></span>
        
            <span class="tag"><a href="../../tags/osrm">osrm</a></span>
        
            <span class="tag"><a href="../../tags/postgis">postgis</a></span>
        
            <span class="tag"><a href="../../tags/postgresql">postgresql</a></span>
        
            <span class="tag"><a href="../../tags/qgis">qgis</a></span>
        
            <span class="tag"><a href="../../tags/r">r</a></span>
        
            <span class="tag"><a href="../../tags/r-packages">r-packages</a></span>
        
            <span class="tag"><a href="../../tags/seasonal-adjustment">seasonal-adjustment</a></span>
        
            <span class="tag"><a href="../../tags/sedona">sedona</a></span>
        
            <span class="tag"><a href="../../tags/shiny">shiny</a></span>
        
            <span class="tag"><a href="../../tags/spark">spark</a></span>
        
            <span class="tag"><a href="../../tags/tiles">tiles</a></span>
        
            <span class="tag"><a href="../../tags/tilestache">tilestache</a></span>
        
            <span class="tag"><a href="../../tags/vuejs">vuejs</a></span>
        
            <span class="tag"><a href="../../tags/wmts">wmts</a></span>
        
            <span class="tag"><a href="../../tags/wsl2">wsl2</a></span>
        
            <span class="tag"><a href="../../tags/x13-arima-seats">x13-arima-seats</a></span>
        
        </div>          
    </div>
</div><br>
        <div class="card">
    <div class="card-content">
        <h1 class="title is-5">Recent posts</h1>
        
            <h1><a href="../../post/2021-07-16-online-learning-with-apache-kafka/">Online Learning with Apache Kafka</a></h1>
            <time class="has-text-grey-light is-size-7">16 July 2021</time>
        
            <h1><a href="../../post/2021-04-19-a-brief-look-at-apache-sedona/">A Brief Look at Apache Sedona</a></h1>
            <time class="has-text-grey-light is-size-7">19 April 2021</time>
        
            <h1><a href="../../post/2020-12-05-working-productively-on-windows-using-wsl2-and-docker/">Working Productively on Windows Using Windows Subsystem for Linux 2 and Docker</a></h1>
            <time class="has-text-grey-light is-size-7">5 December 2020</time>
        
            <h1><a href="../../post/2020-10-31-using-postgis-as-a-spatial-backend-for-r/">Using PostGIS as a Spatial Backend for R</a></h1>
            <time class="has-text-grey-light is-size-7">31 October 2020</time>
        
            <h1><a href="../../post/2020-10-31-docker-on-windows-with-wsl2/">Docker on Windows with Windows Subsystem for Linux 2</a></h1>
            <time class="has-text-grey-light is-size-7">31 October 2020</time>
        
    </div>
</div>
    <br>
                


    
<br>
        <div class="card">
    <div class="card-content">
        <h1 class="title is-5">Archives</h1>
        
            <a href="../../archives/2021">2021</a> (2)<br>
        
            <a href="../../archives/2020">2020</a> (4)<br>
        
            <a href="../../archives/2019">2019</a> (1)<br>
        
            <a href="../../archives/2017">2017</a> (1)<br>
        
            <a href="../../archives/2016">2016</a> (4)<br>
        
    </div>
</div>

    </div>
</div>


    </div>
</div>

<footer class="footer has-background-grey-darker has-text-white">
    <div class="content has-text-centered">
        <p>
            <span class="icon is-large"><a href="https://github.com/cmhh" class="mysocial" rel="me"><i class="fab fa-github fa-3x"></i></a></span>&nbsp;&nbsp;
            <span class="icon is-large"><a href="mailto://cmhhansen@outlook.com" class="mysocial" rel="me"><i class="fas fa-envelope fa-3x"></i></a></span>&nbsp;&nbsp;
            <br><br>
            Copyright &copy; cmhh 2021 - Theme by <a href="https://jeffprod.com" class="mysocial">JeffProd.com</a>
        </p>
    </div>
</footer>

<script defer src="https://use.fontawesome.com/releases/v5.1.0/js/all.js"></script>
<script src="../../js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script src="//yihui.org/js/math-code.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</body>
</html>
